{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Notebook to get DEM from AIA data using Hannah & Kontar implementation**\n",
    "\n",
    "@Author: David Long\n",
    "@Editor: Mohamed Nedal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "from sys import path as sys_path\n",
    "import os.path\n",
    "import platform\n",
    "import datetime as dt\n",
    "from aiapy.calibrate.prep import correct_degradation\n",
    "import numpy as np\n",
    "import glob\n",
    "import matplotlib\n",
    "# matplotlib.use('Agg')\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib.colors as colors\n",
    "import astropy.units as u\n",
    "from astropy.coordinates import SkyCoord\n",
    "from astropy.io import fits as fits\n",
    "from sunpy.map import Map\n",
    "from sunpy.net import Fido, attrs as a\n",
    "from sunpy.coordinates import propagate_with_solar_surface\n",
    "import scipy.io as io\n",
    "sys_path.append('/home/mnedal/repos/demreg/python')\n",
    "from dn2dem_pos import dn2dem_pos\n",
    "script_path = os.path.abspath('./scripts')\n",
    "if script_path not in sys_path:\n",
    "    sys_path.append(script_path)\n",
    "from general_routines import closest\n",
    "from aiapy.calibrate import register, update_pointing, estimate_error\n",
    "import aiapy.psf\n",
    "import asdf\n",
    "from bisect import bisect_left, bisect_right\n",
    "from sunpy.time import parse_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define constants and make the data directories\n",
    "if platform.system() == 'Linux':\n",
    "    data_disk = '/home/mnedal/data/AIA/'\n",
    "\n",
    "os.makedirs(data_disk, exist_ok='True')\n",
    "\n",
    "## Function with event information\n",
    "start_time = '2024/05/14 17:00:00'\n",
    "end_time   = '2024/05/14 19:00:00'\n",
    "\n",
    "cadence = 10*u.second #seconds\n",
    "img_time_range = [dt.datetime.strptime(start_time, \"%Y/%m/%d %H:%M:%S\"), dt.datetime.strptime(end_time, \"%Y/%m/%d %H:%M:%S\")]\n",
    "\n",
    "ref_time = '2012/06/14 01:00:00'\n",
    "bottom_left = [1381, 881]*u.pixel  \n",
    "top_right   = [2215, 1881]*u.pixel  \n",
    "\n",
    "ref_file_date = dt.datetime.strftime(dt.datetime.strptime(ref_time,'%Y/%m/%d %H:%M:%S'), '%Y/%m/%d')\n",
    "img_file_date = dt.datetime.strftime(dt.datetime.strptime(ref_time,'%Y/%m/%d %H:%M:%S'), '%Y/%m/%d')\n",
    "\n",
    "## Define and make the output directories\n",
    "if platform.system() == 'Linux':\n",
    "    output_dir = f'{data_disk}/DEM/{img_file_date}/'\n",
    "\n",
    "os.makedirs(output_dir, exist_ok='True')\n",
    "passband = [94, 131, 171, 193, 211, 335]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Function to get the list of AIA filenames\n",
    "def get_filelist(data_disk, passband, img_file_date):\n",
    "    files = glob.glob(data_disk+str(passband).rjust(4, \"0\")+'/'+img_file_date+'/*.fits', recursive=True)\n",
    "    files.sort()\n",
    "    files_dt = []\n",
    "    for file_i in files:\n",
    "        hdr = fits.getheader(file_i, 1)\n",
    "        try:\n",
    "            files_dt.append(dt.datetime.strptime(hdr.get('DATE-OBS'), '%Y-%m-%dT%H:%M:%S.%fZ'))\n",
    "        except:\n",
    "            files_dt.append(dt.datetime.strptime(hdr.get('DATE-OBS'), '%Y-%m-%dT%H:%M:%S.%f'))\n",
    "    return files, files_dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Function to download data\n",
    "def get_data(start_time, end_time, img_file_date, cadence, pband, data_disk):\n",
    "    ## Identify and download the data\n",
    "    attrs_time = a.Time(start_time, end_time)\n",
    "    wvlnth = a.Wavelength(int(pband)*u.Angstrom, int(pband)*u.Angstrom)\n",
    "    result = Fido.search(attrs_time, a.Instrument('AIA'), wvlnth, a.Sample(cadence))\n",
    "    files = Fido.fetch(result, path=data_disk+str(pband).rjust(4, '0')+'/'+img_file_date, overwrite=False, progress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Function to reduce filerange to within time range of interest\n",
    "def reduce_filerange(files_in, file_time_in, img_time_range):\n",
    "    left = bisect_left(file_time_in, img_time_range[0])\n",
    "    right = bisect_right(file_time_in, img_time_range[1])\n",
    "    files_out = files_in[left:right]\n",
    "    file_time_out = file_time_in[left:right]\n",
    "    return files_out, file_time_out"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the data for the field of view reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "strt_time = dt.datetime.strptime(ref_time, \"%Y/%m/%d %H:%M:%S\")\n",
    "\n",
    "files, files_dt = get_filelist(data_disk, 193, ref_file_date)\n",
    "if not files:\n",
    "    get_data(strt_time-dt.timedelta(seconds=10), strt_time+dt.timedelta(seconds=10), ref_file_date, 10*u.second, 193, data_disk)\n",
    "\n",
    "files, files_dt = get_filelist(data_disk, 193, ref_file_date)\n",
    "\n",
    "ind = np.abs([t - strt_time for t in files_dt])\n",
    "map = Map(files[ind.argmin()])\n",
    "    \n",
    "pix_width = [(top_right[0]-bottom_left[0])/2, (top_right[1]-bottom_left[1])/2]\n",
    "pix_centre = [pix_width[0]+bottom_left[0], pix_width[1]+bottom_left[1]]\n",
    "crd_bl = SkyCoord(map.pixel_to_world(bottom_left[0], bottom_left[1]), frame=map.coordinate_frame)\n",
    "crd_tr = SkyCoord(map.pixel_to_world(top_right[0], top_right[1]), frame=map.coordinate_frame)\n",
    "    \n",
    "crd_cent = SkyCoord(map.pixel_to_world(pix_centre[0], pix_centre[1]), frame=map.coordinate_frame)\n",
    "crd_width = [(crd_tr.Tx.arcsecond-crd_bl.Tx.arcsecond)/2, (crd_tr.Ty.arcsecond-crd_bl.Ty.arcsecond)/2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Function to get AIA submap\n",
    "def get_submap(time_array,index,img,f_0171,crd_cent,crd_width):\n",
    "    ind_0171 = closest(np.array(time_array[2][:]), time_array[index][img])\n",
    "    map = Map(f_0171[ind_0171])\n",
    "    with propagate_with_solar_surface():\n",
    "        diffrot_cent = crd_cent.transform_to(map.coordinate_frame)\n",
    "    bl = SkyCoord((diffrot_cent.Tx.arcsecond-crd_width[0])*u.arcsec, (diffrot_cent.Ty.arcsecond-crd_width[1])*u.arcsec, frame=map.coordinate_frame)\n",
    "    tr = SkyCoord((diffrot_cent.Tx.arcsecond+crd_width[0])*u.arcsec, (diffrot_cent.Ty.arcsecond+crd_width[1])*u.arcsec, frame=map.coordinate_frame)\n",
    "    submap = map.submap(bl, top_right=tr)\n",
    "    return submap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Function to prep AIA images, deconvolve with PSF and produce submap\n",
    "def prep_images(time_array, index, img, f_0094, f_0131, f_0171, f_0193, f_0211, f_0335, crd_cent, crd_width):\n",
    "    ind_0094 = closest(np.array(time_array[0][:]), time_array[index][img])\n",
    "    ind_0131 = closest(np.array(time_array[1][:]), time_array[index][img])\n",
    "    ind_0171 = closest(np.array(time_array[2][:]), time_array[index][img])\n",
    "    ind_0193 = closest(np.array(time_array[3][:]), time_array[index][img])\n",
    "    ind_0211 = closest(np.array(time_array[4][:]), time_array[index][img])\n",
    "    ind_0335 = closest(np.array(time_array[5][:]), time_array[index][img])\n",
    "\n",
    "    farray = [f_0094[ind_0094], f_0131[ind_0131], f_0171[ind_0171], f_0193[ind_0193], f_0211[ind_0211], f_0335[ind_0335]]\n",
    "    maps = Map(farray)\n",
    "    with propagate_with_solar_surface():\n",
    "        diffrot_cent = crd_cent.transform_to(maps[0].coordinate_frame)\n",
    "    bl = SkyCoord((diffrot_cent.Tx.arcsecond-crd_width[0])*u.arcsec, (diffrot_cent.Ty.arcsecond-crd_width[1])*u.arcsec, frame=maps[0].coordinate_frame)\n",
    "    bl_x, bl_y = maps[0].world_to_pixel(bl)\n",
    "    tr = SkyCoord((diffrot_cent.Tx.arcsecond+crd_width[0])*u.arcsec, (diffrot_cent.Ty.arcsecond+crd_width[1])*u.arcsec, frame=maps[0].coordinate_frame)\n",
    "    tr_x, tr_y = maps[0].world_to_pixel(tr)\n",
    "    submap_0 = maps[0].submap([int(bl_x.value), int(bl_y.value)]*u.pixel, top_right=[int(tr_x.value), int(tr_y.value)]*u.pixel)\n",
    "    nx, ny = submap_0.data.shape\n",
    "    nf=len(maps)\n",
    "\n",
    "    print('Prepping images & deconvolving with PSF')\n",
    "    map_arr = []\n",
    "    error_array = np.zeros([nx, ny, nf])\n",
    "\n",
    "    for m in range(0, len(maps)):\n",
    "        psf = aiapy.psf.psf(maps[m].wavelength)\n",
    "        aia_map_deconvolved = aiapy.psf.deconvolve(maps[m], psf=psf)\n",
    "        aia_map_updated_pointing = update_pointing(aia_map_deconvolved)\n",
    "        aia_map_registered = register(aia_map_updated_pointing)\n",
    "        aia_map_corrected = correct_degradation(aia_map_registered)\n",
    "        aia_map_norm = aia_map_corrected/aia_map_corrected.exposure_time\n",
    "        submap = aia_map_norm.submap([int(bl_x.value), int(bl_y.value)]*u.pixel, top_right=[int(tr_x.value), int(tr_y.value)]*u.pixel)\n",
    "        map_arr.append(submap)\n",
    "        num_pix = submap.data.size\n",
    "        error_array[:,:,m] = estimate_error(submap.data*(u.ct/u.pix),submap.wavelength,num_pix)\n",
    "\n",
    "    map_array = Map(map_arr[0], map_arr[1], map_arr[2], map_arr[3],\n",
    "                    map_arr[4], map_arr[5], sequence=True, sortby=None) \n",
    "    print('Images prepped & region of interest selected')\n",
    "    return map_array, error_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Function to calculate DEM\n",
    "def calculate_dem(map_array, err_array):\n",
    "    nx,ny = map_array[0].data.shape\n",
    "    nf = len(map_array)\n",
    "    image_array = np.zeros((nx, ny, nf))\n",
    "    for img in range(0, nf):\n",
    "        image_array[:,:,img] = map_array[img].data\n",
    "\n",
    "    if platform.system() == 'Linux':\n",
    "        trin = io.readsav('/disk/solar2/dml/idl/aia_tresp_en.dat')\n",
    "        \n",
    "    tresp_logt = np.array(trin['logt'])\n",
    "    nt = len(tresp_logt)\n",
    "    nf = len(trin['tr'][:])\n",
    "    trmatrix = np.zeros((nt,nf))\n",
    "    for i in range(0,nf):\n",
    "        trmatrix[:,i] = trin['tr'][i]    \n",
    "    \n",
    "    t_space = 0.1\n",
    "    t_min = 5.6\n",
    "    t_max = 7.4\n",
    "    logtemps = np.linspace(t_min, t_max, num=int((t_max-t_min)/t_space)+1)\n",
    "    temps = 10**logtemps\n",
    "    mlogt = ([np.mean([(np.log10(temps[i])), np.log10((temps[i+1]))]) for i in np.arange(0,len(temps)-1)])\n",
    "    dem, edem, elogt, chisq, dn_reg = dn2dem_pos(image_array, err_array, trmatrix, tresp_logt, temps, max_iter=15)\n",
    "    dem = dem.clip(min=0)\n",
    "    return dem, edem, elogt, chisq, dn_reg, mlogt, logtemps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Function to plot the DEM images\n",
    "def plot_dem_images(submap, dem, logtemps, img_arr_tit):\n",
    "    nt = len(dem[0,0,:])\n",
    "    nt_new = int(nt/2)\n",
    "    nc, nr = 3, 3\n",
    "    plt.rcParams.update({'font.size':12, 'font.family':\"sans-serif\",\\\n",
    "                         'font.sans-serif':\"Arial\", 'mathtext.default':\"regular\"})\n",
    "    fig, axes = plt.subplots(nrows=nr, ncols=nc, figsize=(10,12), sharex=True, sharey=True, subplot_kw=dict(projection=submap), layout='constrained')\n",
    "    plt.suptitle('Image time = '+dt.datetime.strftime(submap.date.datetime, \"%Y-%m-%dT%H:%M:%S\"))\n",
    "    fig.supxlabel('Solar X (arcsec)')\n",
    "    fig.supylabel('Solar Y (arcsec)')\n",
    "    cmap = plt.cm.get_cmap('cubehelix_r')\n",
    "\n",
    "    for i, axi in enumerate(axes.flat):\n",
    "        new_dem = (dem[:,:,i*2]+dem[:,:,i*2+1])/2.\n",
    "        plotmap = Map(new_dem, submap.meta)\n",
    "        plotmap.plot(axes=axi, norm=colors.LogNorm(vmin=1e19, vmax=1e22), cmap=cmap)\n",
    "    \n",
    "        y = axi.coords[1]\n",
    "        y.set_axislabel(' ')\n",
    "        if i == 1 or i == 2 or i == 4 or i == 5 or i == 7 or i == 8:\n",
    "            y.set_ticklabel_visible(False)\n",
    "        x = axi.coords[0]\n",
    "        x.set_axislabel(' ')\n",
    "        if i < 6:\n",
    "            x.set_ticklabel_visible(False)\n",
    "\n",
    "        axi.set_title(f'Log(T) = {logtemps[i*2]:.2f} - {logtemps[i*2+1+1]:.2f}')\n",
    "\n",
    "    plt.tight_layout(pad=0.1, rect=[0, 0, 1, 0.98])\n",
    "    plt.colorbar(ax=axes.ravel().tolist(), label='$\\mathrm{DEM\\;[cm^{-5}\\;K^{-1}]}$', fraction=0.03, pad=0.02)\n",
    "    plt.savefig(img_arr_tit, bbox_inches='tight')\n",
    "    plt.close(fig)\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## START FROM HERE ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Download the data\n",
    "for pband in passband:\n",
    "    files, file_time = get_filelist(data_disk, pband, img_file_date)\n",
    "    left = bisect_left(file_time, img_time_range[0])\n",
    "    right = bisect_right(file_time, img_time_range[1])\n",
    "    n_img = ((img_time_range[1]-img_time_range[0]).total_seconds()/(cadence/u.second))\n",
    "\n",
    "    if n_img > len(files[left:right]):\n",
    "        print('Fewer than expected FITS files for '+str(pband).rjust(4, \"0\")+' passband')\n",
    "        print('Downloading data for '+str(pband).rjust(4, \"0\")+' passband')\n",
    "        get_data(start_time, end_time, img_file_date, cadence, pband, data_disk)\n",
    "    else:\n",
    "        print('Data already downloaded for '+str(pband).rjust(4, \"0\")+' passband')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get list of files from each passband to identify the smallest number of files\n",
    "print('Getting list of files')\n",
    "f_0094, time_0094 = get_filelist(data_disk, 94, img_file_date)\n",
    "f_0094, time_0094 = reduce_filerange(f_0094, time_0094, img_time_range)\n",
    "\n",
    "f_0131, time_0131 = get_filelist(data_disk, 131, img_file_date)\n",
    "f_0131, time_0131 = reduce_filerange(f_0131, time_0131, img_time_range)\n",
    "\n",
    "f_0171, time_0171 = get_filelist(data_disk, 171, img_file_date)\n",
    "f_0171, time_0171 = reduce_filerange(f_0171, time_0171, img_time_range)\n",
    "\n",
    "f_0193, time_0193 = get_filelist(data_disk, 193, img_file_date)\n",
    "f_0193, time_0193 = reduce_filerange(f_0193, time_0193, img_time_range)\n",
    "\n",
    "f_0211, time_0211 = get_filelist(data_disk, 211, img_file_date)\n",
    "f_0211, time_0211 = reduce_filerange(f_0211, time_0211, img_time_range)\n",
    "\n",
    "f_0335, time_0335 = get_filelist(data_disk, 335, img_file_date)\n",
    "f_0335, time_0335 = reduce_filerange(f_0335, time_0335, img_time_range)\n",
    "\n",
    "flength = [len(f_0094), len(f_0131), len(f_0171), len(f_0193), len(f_0211), len(f_0335)]\n",
    "flist = [f_0094, f_0131, f_0171, f_0193, f_0211, f_0335]\n",
    "time_array = [time_0094, time_0131, time_0171, time_0193, time_0211, time_0335]\n",
    "index = np.argmin(flength)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Begin image processing\n",
    "start_img = closest(np.array(time_array[index][:]), dt.datetime.strptime(start_time, \"%Y/%m/%d %H:%M:%S\"))\n",
    "\n",
    "for img in range(start_img, len(flist[index])):\n",
    "    print('Processing image, time = '+dt.datetime.strftime(time_array[index][img], \"%Y-%m-%dT%H:%M:%S\"))\n",
    "\n",
    "    # Get and process images.\n",
    "    err_arr_tit = output_dir+'error_data_'+dt.datetime.strftime(time_array[index][img], \"%Y%m%d_%H%M%S\")+'.asdf'\n",
    "    map_arr_tit = output_dir+'prepped_data_'+dt.datetime.strftime(time_array[index][img], \"%Y%m%d_%H%M%S\")+'_{index:03}.fits'\n",
    "    files = os.path.exists(err_arr_tit)\n",
    "    \n",
    "    if files == False:\n",
    "        map_array, err_array = prep_images(time_array, index, img, f_0094, f_0131, f_0171, f_0193, f_0211, f_0335, crd_cent, crd_width)\n",
    "        map_array.save(map_arr_tit, overwrite='True')\n",
    "        tree = {'err_array': err_array}\n",
    "        with asdf.AsdfFile(tree) as asdf_file:\n",
    "            asdf_file.write_to(err_arr_tit, all_array_compression='zlib')\n",
    "    else:\n",
    "        print('Loading previously prepped images')\n",
    "        arrs = asdf.open(err_arr_tit)\n",
    "        err_array = arrs['err_array']\n",
    "        ffin=sorted(glob.glob(output_dir+'prepped_data_'+dt.datetime.strftime(time_array[index][img], \"%Y%m%d_%H%M%S\")+'*.fits'))\n",
    "        map_array = Map(ffin)\n",
    "    \n",
    "    # Calculate DEMs\n",
    "    dem_arr_tit = output_dir+'dem_data_'+dt.datetime.strftime(time_array[index][img], \"%Y%m%d_%H%M%S\")+'.asdf'\n",
    "    files = os.path.exists(dem_arr_tit)\n",
    "    \n",
    "    if files == False:\n",
    "        print('Calculating DEM')\n",
    "        dem, edem, elogt, chisq, dn_reg, mlogt, logtemps = calculate_dem(map_array, err_array)\n",
    "        tree = {'dem':dem, 'edem':edem, 'mlogt':mlogt, 'elogt':elogt, 'chisq':chisq, 'logtemps':logtemps}\n",
    "        with asdf.AsdfFile(tree) as asdf_file:  \n",
    "            asdf_file.write_to(dem_arr_tit, all_array_compression='zlib')\n",
    "    else:\n",
    "        print('Loading previously calculated DEM')\n",
    "        arrs = asdf.open(dem_arr_tit)  \n",
    "        dem = arrs['dem']\n",
    "        edem = arrs['edem']\n",
    "        mlogt = arrs['mlogt']\n",
    "        elogt = arrs['elogt']\n",
    "        chisq = arrs['chisq']\n",
    "        logtemps = arrs['logtemps']\n",
    "\n",
    "    # Plot results\n",
    "#    img_tit = output_dir+'Centre_pixel_DEM_'+dt.datetime.strftime(time_array[index][img], \"%Y%m%d_%H%M%S\")+'.png'\n",
    "#    plot_dem(dem,edem,mlogt,elogt,img_tit)\n",
    "\n",
    "    # Get a submap to have the scales and image properties.\n",
    "    submap = get_submap(time_array, index, img, f_0171, crd_cent, crd_width)\n",
    "    img_arr_tit = output_dir+'DEM_images_'+dt.datetime.strftime(time_array[index][img], \"%Y%m%d_%H%M%S\")+'.png'\n",
    "    plot = plot_dem_images(submap, dem, logtemps, img_arr_tit)\n",
    "    print('DEM plotted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dias",
   "language": "python",
   "name": "dias"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "d9d63a95916665a063324d634de36681bd679ce36f6a9eeb7ba063d62a847613"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
